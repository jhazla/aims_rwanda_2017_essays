\chapter{Introduction of the Research}
\Jnote{Change to ``Introduction''.}

In every organization there is a way to communicate. One of the most popular way to transmit the information  is  to produce a written report which explains how different activities of the organization are going. For large organizations there are huge number of reports and it is so
\Jnote{Delete ``so''.}
challenging to go through  each and every report manually.
This research has an aim of providing an easy way of visualizing and extracting the important information locked in reports from NGO
\Jnote{s/NGO/NGOs}
and large organisations.

In 1919, the International Federation of Red Cross and Red Crescent societies (IFRC) has been founded, it has some millions of reports related to humanitarian support,
\Jnote{Change comma to full stop.}
How to  know automatically the number of people who suffered from a disease?  How to know the  fraction of fund spent on shelter?  

In this research, we tried to use a combination of statistics formulae  and techniques of Natural Language Processing (NLP) to find the solution for the extracting entities, 
Big data and Machine learning for analysing the huge data by using statistical and computing algorithms.
\Jnote{This sentence is too long, split it into two thoughts.}
Entity can be defined as an instance of existence of something, for example what is the activity done on what place when and how ?
\Jnote{No space before question mark.}

Document modelling by extracting entities is one of the way to deal with natural big data linguistic problems where entity can be considered as a single unit of data like location, people, organization and so on. Entities  can be classified based on their relationship.

These are key procedures to be performed for extracting entities: 
\begin{itemize}
\item The sentences which compose a report  must be parsed.
\item Entities must be identified in the report and classified.
\item Relationship between entities must be modelled.
\end{itemize}

A report is composed by
\Jnote{s/by/of}
paragraphs, each paragraph is made by sentences. Natural  Language Processing techniques deal with sentences and content based analysis by splitting the sentences into tokens
then remove the common words and work with corpus to get entities.
\Jnote{s/remove/removing, s/and work/in order to work. Consider splitting this
sentence into two.}
The meaning of a word can depend on its surroundings as well as it can be independent.
\Jnote{s/as well as it can be independent/but it can also be independent of it}
For extracting significant entities, the context of a word is one of the points to be considered carefully.