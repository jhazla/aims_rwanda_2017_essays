\chapter{Parallel repetition of multi-prover games.}


In this chapter we discuss about the parallel repetition of multi-prover games. Firstly, some notions about two-prover games are presented. Then, a generalisation to multiple  provers is given. In the end, these notions are followed by notions about parallel repetition in which is presented the theorem that expresses the upper bound of the value of the success probability of the parallel repetition of multi-prover games.


\section{Two-prover games.}


\subsection{Definitions} \label{tpg}

Consider a cooperative game $G$  of incomplete information played between two persons  (Player 1 and Player 2) 
\citep{ben1988multi, verbitsky1996towards, raz2010parallel}.
%\Jnote{Change to: Consider a cooperative game...}
A \textit{two-prover one round  game} or simply \textit{two-prover game} (often called \textit{game} in this work for short) is a game played between two players called \textit{prover} and an additional player called \textit{verifier} or \textit{referee.}
%\Jnote{No, MIP is something else (it is a class of languages). Please delete this sentence.}
Notice that a two-prover game is a concept originating from theoretical computer science. Let us introduce some basic idea of this game.

Let $X, Y, S, T$ be  finite sets. Let $Q$ be a subset of $X\times Y$ ( that is $Q \subseteq X \times Y$ can represent a set of pair of questions: $X$ represent the set of possible questions for the first prover and $Y$ a set of possible questions for the second prover).    $S$ and $T$ can be interpreted respectively as set of possible answers associated respectively to $X$ and $Y$.

A pair $(x,y) \in_{\mu} Q \subseteq X\times Y$ of questions is chosen randomly  by the verifier, that is with a probability distribution measure $\mu: Q \longmapsto \mathbb{R}^+.$
%\Jnote{Is it chosen uniformly or according to $\mu$?}
%\Jnote{Actually, $\mu: Q \to \mathbb{R}^+$.}
The verifier sends $x$ to the first prover and $y$ to the second prover. Each prover does not know the question addressed to the other and the communication during the game is not allowed. Nevertheless, before the game starts, they are allowed to agree on a strategy that will help them to increase the probability of winning the game. Let us introduce some main idea of this strategy. 

The \textit{strategy} used to answer 
the pair of questions $(x,y)$
%\Jnote{s/answer to the pair/answer the pair}
is a pair of functions $(f,h)$ defined as: $f: X \longrightarrow S: x \longmapsto f(x)$ and $h: Y \longrightarrow T: y \longmapsto h(y).$
That is, $f(x) \in S$ is the answer to the question $x$
%\Jnote{s/answer of question/answer to question}
using the strategy $f$ by prover 1. Whereas $h(y) \in T$ is the answer to the question $y$ using the strategy $h$ by prover 2.

The role of the verifier is to accept or reject the answers given from both provers. Thus, the verifier is also a function. We denote the function  \say{\textit{verifier}}
%\Jnote{Use Latex quotes (open with ``, close with ''), look at the code to see   the difference.}
by $\phi$ and defined as: $\phi: (X,Y,S,T) \longrightarrow \{0,1\}: (x,y,f(x),h(y)) \longmapsto  \phi(x,y,f(x),h(y)).$ $\phi$ is a predicate on  $(X,Y,S,T).$

If $\phi(x,y,f(x),h(y))=1$, then the two players win. They lose if $\phi(x,y,f(x),h(y))=0.$ 

In sum, in this case $G=(\phi, Q\subseteq X \times Y, S,T, \mu)$ represents  a game if $X,Y,S,T$ are finite set,
%\Jnote{s/subset/sets}
the function $\phi: Q\times S \times T  \longmapsto \{0,1\}$ is a predicate, and $\mu$ is a probability distribution measure. 
%That is, a prover game is a tuple.
%\Jnote{Delete last sentence. Formally it is a tuple, but it is not important.}

Prover games become interesting when we want to estimate the probability of winning the game according to the strategies used, and mainly when several questions are addressed simultaneously  to each prover.

Let $\Pr[\phi(x,y,f(x),h(y))=1]$
%\Jnote{Use \textbackslash Pr to denote probability in math mode.}
be the winning probability associated to the one of the couples $(f,h)$ of the strategies. In this case, the winning probability \say{ $\Pr$} which can be the expectation is taken over the distribution $\mu.$
%\Jnote{s/expectation is taken to/expectation taken over}

As in all games, the aim of the two players is to maximize the winning probability according to their strategies. Let denote by $\val (G)$ the \textit{value} of the winning probability associated to the optimal couple of strategies of the two provers for the game $G$ where the probability is taken over the couple $(x,y) \in_{\mu} Q$. Then, $\val (G)$ is expressed as: $$\val (G)=\max_{f,h}  \underset{(x,y) \sim Q}\Pr[\phi(x,y,f(x),h(y))=1]$$
%\Jnote{Indicate over what the probability is taken.}
where $\underset{(x,y) \sim Q}\Pr$ means that the probability is taken over the couple $(x,y) \in_{\mu} Q$ and $\max\limits_{f,h}$ means that the maximum winning probability  is taken over all possible couples of strategies $(f,g).$

When $\val (G)=1$, the game $G$ is called \textit{trivial}. In mostly of cases, we will consider a \textit{non-trivial} game, 
%\Jnote{Space before comma.}
that is a prover game with $\val (G) \neq 1.$
The two-prover game $G$ is called a \textit{free game} if $Q=X \times Y$, that is, questions to players are  independent. Another definition of a free game using the probability distribution 
% \cite*{barak2009strong}\Jnote{Don't cite here, this is a common definition.}
is when  the probability  distribution of the questions is a product probability  distribution, that is $\mu_{XY}=\mu_X \mu_Y.$
The probability distribution $\mu_{XY}$ is  the joint distribution according to which the verifier chooses a pair of questions to the provers. $\mu_X$ (respectively  $\mu_Y$) the probability distribution for the verifier to choose a question in the set $X$ (respectively $Y$).

A two-prover game $G$ is called \textit{projection game} if for every pair of questions $(x,y) \in X \times Y$ there is a function $f_{x,y}: T \longmapsto S$, such that, for every $a\in S, \ b\in T$, we have: $\phi(x,y,a,b)=1$ if and only if $f_{x,y}(b)=a.$ 

The game $G$ is \textit{unique} if for every $(x,y) \in X \times Y$ the function $f_{x,y}$ is a bijection. Hence, a unique game is a particular case of a projection game. 

When sets $T, S = \{0, 1\}$, then the unique game is called a \textit{XOR} game. That is, when sets of question are composed only of $0$ and $1.$
%\Jnote{s/only by/only of}

There are more special kinds of prover games considered in the literature \citep*{verbitsky1996towards, cleve2007perfect, raz2010parallel, rao2011parallel, moshkovitz2014parallel, tamaki2015parallel, bavarian2015anchoring, dinur2016multiplayer, hkazla2016forbidden}.
%\cite{raz2010parallel} gave three nice definitions of kinds of prover games: projection game, unique game and XOR game.
%\Jnote{Change this: There are more special kinds of games
%  considered in the literature (cite Raz).}

\subsection{Relationship between graphs and two-prover games} \label{expander}

The relationship between graphs and two-prover games is broad. Thus, in this part we present an elementary  relationship by introducing a two-prover game through basic notions of graphs. Some advanced connections have been studied by
%\Jnote{s/are/have}
\cite*{laekhanukit2014parameters,tamaki2015parallel,dinur2016multiplayer}.

Let $X$, $Y$ be two vertex sets of a bipartite graph. $E\subseteq X \times Y$ an edge set, $L$ a label set which can for instance contain some colours. By $c_e$ we denote a set of constraints associated to edge $e \in E$, for example  this constraint can be colouring vertices of edge $e$ with different colours chosen in $L$. Thus, $c_e \subseteq L \times L$.
%\Jnote{Say that $c_e \subseteq L \times L$}

In this case for graphs, a two-prover game $G$ is the game $G=(X,Y,E,L,C)$ where $C=\{c_e\}_{e\in E}$ is the set of (sets of) constraints associated to edges $e \in E$.
In others words, a two-prover game G consists of a bipartite graph with vertex
sets $X$, $Y$, an edge set $ E \subseteq X \times Y$, a label set $L$ and a set of constraints associated to edges. Note that this definition is not equivalent to the first one.

%\Jnote{You are giving a definition that is not equivalent to your previous definition. You should not call two different things with the same name.   At the very least you should make clear that this definition is not equivalent   to the first one.}

Let us define two functions $f$ and $g$ which assign colours to each vertices  $x \in X$ and $y \in Y$ by $f: X\longmapsto L$ and $g: Y\longmapsto L$. We say that $f$ and $g$ satisfy the constraint $c_{(x,y)}$ if $(f(x),g(y)) \in c_{(x,y)}$, that is if $f(x)$ and $g(y)$ satisfy the constraints in $c_{(x,y)}$. So, the value of the game is the success probability to find a couple of functions $(f,g)$ that assigns the maximum of colours.
%\Jnote{Maximum of colors?}
\cite{tamaki2015parallel} expresses this value as follows: 
 $$\val (G)=\max_{f,g}\underset{(x,y)\sim E}\Pr  \{(f(x),g(y)) \in c_{(x,y)} \}$$
where the probability is taken over the edge $(x,y) \in E$ and the maximum of probability is taken over all optimal couple of strategies $(f,g).$

\subsection{Expander graphs}

Prover games used to be associated to the expander graph. Expander graph has some interesting properties. 
\cite{nielsen2005introduction} defines an expander graph as \say{\emph{ a graph $G = (V, E)$ in which every subset $S$ of vertices expands quickly, in the sense that it is connected to many vertices in the set $S$ of complementary vertices.}} Expander graph is characterized by some expansion parameters: vertex expansion, edge expansion and spectral expansion. The spectral gap denoted by $\lambda$, namely the difference between the largest and second-largest eigenvalues is used to measure the spectral expansion. 

The connectedness  property is one of the fundamental properties of expander graph. Thus, every connected graph is an expander. Hence, a cycle graph and a complete graph are expander graph.

An expander graph is based on regular graph. A good expander graph is an expander which has high expansion parameters and a low degree.  For instance, a random graph is a good expander graph. However a complete graph is not a good expander graph because it has the largest degree although it has the best expansion properties.


 \subsection{Multi-prover games.} The rules of the multi-prover games are similar to two-prover games. But, as indicated by the term "multi", this game is played
% \Jnote{s/playing/played}
 with several provers (more than two players). That is, we are dealing with the general case.

Let us consider that there are $k$-prover, with $k \geq 2$. A $k$-prover  game is the game $G(\phi, Q \subseteq X^1  \times \cdots \times X^k , A^1 , \cdots,  A^k, \mu) $. So, $k$-tuple of questions $(x^1, \cdots , x^k) \in_{\mu} Q \subseteq X^1  \times \cdots \times X^k $ (with $X^t$ set of questions)
%\Jnote{What are $i$ and $t$?}
is chosen with probability distribution measure $\mu $ from a set of question,
and the answer is a $k$-tuple vector $(a^1, \cdots , a^k)  \in A^1 \times \cdots \times A^k$ (with $A^t$ set of answers) according to question $(x^1, \cdots , x^k).$ The distribution measure $\mu $ associates an element of $ Q \subseteq  X^1  \times \cdots \times X^k $ to an element of $\mathbb{R}^+ \cap [0,1]= (0, 1].$
%\Jnote{$\mathbb{R}^+ \cap [0,1] = (0, 1].$}
A verifier chooses $k$-tuple of questions $(x^1, \cdots , x^k)$ and sends a question $x^t$ to the prover $t$. The answer $a^t$ of the prover $t$ depends only on the question $x^t.$ As for two-prover games, the players cannot communicate during the game, but they are allowed to agree on a strategy. 

In this case, the strategy used to answer is a $k$-tuple of functions $(f^1, \cdots , f^k)$ defined as:
$f^t: X^t \longrightarrow A^t: x^t \longmapsto f^t(x^t)=a^t$, for $1\leq t \leq k.$

The predicate (verifier) on $( X^1 \times \cdots \times X^k, A^1 \times \cdots \times A^k)$ is defined as a function $\phi$:
\begin{align*}
\phi : & X^1 \times \ldots \times X^k \times A^1 \times \ldots \times A^k \longmapsto \{0,1\} \\
& (x^1, \cdots , x^k, f^1(x^1), \cdots , f^k(x^k)) \longmapsto \phi (x^1, \cdots , x^k, f^1(x^1), \cdots , f^k(x^k)).
\end{align*}

All players win if $\phi (x^1, \cdots , x^k, f^1(x^1), \cdots , f^k(x^k))=1.$ 

Thus, the value of the multi-prover game $G$ denoted by $\val (G)$ is  the optimal winning probability of provers over all possible strategies. This value is expressed as follows:
$$\val (G)= \max_{f^1, \cdots , f^k} \Pr[\phi (x^1, \cdots , x^k, f^1(x^1), \cdots , f^k(x^k))=1].$$



\section{Parallel repetition.}

\subsection{Parallel repetition for  two-prover games} \label{prtp}

Let $G$ be a two-prover game and $n$ a positive integer. Knowing the value of the game $G$, we are interested 
%\Jnote{s/interesting/interested}
to establish the relationship between $\val (G)$ and $\val (G^n).$  By executing  $n$ independent copies of $G$ in parallel, we obtain what we call an $n-$\textit{product game G} or a \textit{product game} $G^n$ or an \textit{n-fold parallel repetition} $G^n.$ Hence, a parallel repetition of a two-prover game $G$ is a product game $G^n$, that is approximately
%\Jnote{s/approximatively/approximately}
speaking when $n$ copies of the game $G$ is tried to be won simultaneously by the two players. The game $G$ is called  the \textit{base game} of the parallel repeated game $G^n.$

According to the definition of a prover $G$, let $G(\phi, Q \subseteq X \times Y, S, T, \mu)$ be a game. The product game $G^n$ is the game $G^n(\phi^n, Q^n\subseteq X^n \times Y^n, S^n, T^n, \mu^n)$, where $\phi^n$ represents a predicate (referee or verifier), $Q^n$ a product set of questions, $S^n$ and $T^n$ represent sets of answers, and $\mu^n$ represents the probability distribution measure. Let us express explicitly the sets $Q^n$ and the functions $\mu^n$ and $\phi^n.$

 Elements of $Q^n$ take the form $((x_1, y_1),(x_2,y_2 ), \ldots, (x_n, y_n))$ where $x_1, x_2, \ldots, x_n \in X$ and $y_1, y_2, \ldots, y_n \in Y$, that is a collection of $n$-tuple of couples  $((x_1, y_1),(x_2,y_2 ), \ldots, (x_n, y_n))$ is chosen randomly and uniformly from the set $Q^n$ in accordance with the probability distribution measure $\mu^n $. The element  $((x_1, y_1),(x_2,y_2 ), \ldots, (x_n, y_n)) \in Q^n$ is  identified to the pair $((x_1,\ldots, x_n), (y_1, \ldots, y_n)) \in Q^n \subseteq X^n \times Y^n.$
 
Thus, the probability measure $\mu^n$ can be expressed as a function using $\mu$: 
 \begin{align*}
\mu^n:  & Q^n \subseteq X^n \times Y^n  \longrightarrow \mathbb{R}^+ \\
  & ((x_1,\ldots, x_n), (y_1,\ldots, y_n)) \longmapsto \mu^n((x_1,\ldots, x_n), (y_1,\ldots, y_n))=\prod_{i=1}^n  \mu (x_i, y_i). 
 \end{align*}
 
We denote by  $\bar{x}$ the $n$-tuple $(x_1,\ldots, x_n)$, that is $\bar{x}=(x_1,\ldots, x_n)$. 

The function $\phi^n$ is defined similarly to the function $ \phi$ as:
\begin{align*}
\phi^n: & X^n \times Y^n \times S^n \times T^n  \longrightarrow  \{0,1\}\\ 
& (\bar{x}, \bar{y},\bar{s}, \bar{t})  \longmapsto  \phi^n(\bar{x}, \bar{y},\bar{s}, \bar{t}) = \bigwedge\limits_{i=1}^n \phi [x_i,y_i, f_i(\bar{x}), h_i(\bar{y})]
\end{align*}
Where $\bigwedge$ represents the logical connective "AND" (conjunction).
%\Jnote{Very nice explanation so far. You can underline the fact that  $f_i$ is a function of $\overline{x}$ and not just $x_i$.}
Note that $f_i$ is a function of $\bar{x}$ and not just $x_i$  in the expression of the predicate $\phi^n$.

We know that in the truth table for the logical operator "AND", the only case so that the value of two propositions be true is when the two propositions are true. Then, the logical connective $\bigwedge$ from $\phi^n$ can be replaced by $\prod.$ That is,  $\bigwedge\limits_{i=1}^n \phi [x_i,y_i, f_i(\bar{x}), h_i(\bar{y})]=\prod\limits_{i=1}^n  \phi [x_i,y_i, f_i(\bar{x}), h_i(\bar{y})].$

As there are two provers, $n$-vectors (questions) are revealed to each prover:  $(x_1, \ldots , x_n)$ to prover 1 and  $(y_1, \ldots , y_n)$ to prover 2 who both respond with  couple of strategies $(F,H)$ with $F=(f_1, f_2, \ldots, f_n)$ and $H=(h_1, h_2, \ldots, h_n)$ where $f_i$ and $h_i$ represent respectively strategies associated to the questions $\bar{x}$ and $\bar{y}.$
%\Jnote{Now you made mistake: It is not $f_1(x_1)$, but $f_1(\bar{x})$. It is important that you correct it above and below.}

Strategies $F$ and $H$ are functions defined as:
 \begin{align*}
 F: & X^n \longrightarrow S^n\\
 &  \bar{x} \longmapsto F(\bar{x})=(f_1(\bar{x}), \ldots , f_n(\bar{x})) \end{align*}  and 
 \begin{align*} 
 H: & Y^n \longrightarrow T^n\\
 & \bar{y} \longmapsto H(\bar{y})=(h_1(\bar{y}), \ldots , h_n(\bar{y}))
 \end{align*}

Now, the winning case occurs when ${\bigwedge\limits_{i=1}^n \phi [x_i,y_i, f_i(\bar{x}), h_i(\bar{y})]=1}$, that is both provers win if they win concomitantly in all $n$ coordinates. Each of the $n$ copies are treated independently by the referee.

Then, the value of the game $G^n$, that is the success probability is:\begin{align*}
\val (G^n) =\max_{F,H}\Pr \left[\bigwedge\limits_{i=1}^n \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right].
\end{align*}

%Let us notice that the game $G^n$ can be defined inductively as $G^1=G, G^2=G \times G, \ldots, G^n=G\times G^{n-1}.$
%\Jnote{You never introduce what is the product of two games. Better delete
%  this.}
 
The winning probability of $G^n$ and the one of $G$ are linked by these relations: \begin{align} \val (G)^n \leq \val (G^n) \leq \val (G). \label{3val}\end{align}

Let us show the inequalities in \eqref{3val} by splitting them into two parts: 
\begin{align}
\left\lbrace \begin{array}{c} \val (G)^n \leq \val (G^n) \\ \val (G^n) \leq \val (G).  \end{array}\right.
\end{align}

\begin{itemize}
\item The first inequality $\val (G)^n \leq \val (G^n) .$

\begin{proof}
We know that the value of the game $G$ is the optimal winning probability of provers over all possible strategies, that is the winning probability using the best couple of strategies. Le us denote by $(f,h)$ this optimal couple of strategies used for the game $G$. Strategies $f$ and $h$ are  defined as $f: X\longrightarrow S$ and  $h: Y\longrightarrow T.$  Then, $\val (G)= \max\limits_{f,g} \Pr[\phi(x,y,f(x),h(y))=1].$

As far as, let us denote by $(F,H)$ a couple of strategies  used  to win the game $G^n$. $F$ and $G$ are $n-$tuple defined as: $F=(f_1, \ldots, f_n)$ and  $H=(h_1, \ldots, h_n)$. Strategies $F$ and $H$ are  defined as $F: X^n\longrightarrow S^n$ and  $H: Y^n\longrightarrow T^n.$ Here, notice that the couple $(F,H)$ of strategies are not necessary the optimal.
Then, the winning probability according to this couple of strategies is: $\Pr \left[\bigwedge\limits_{i=1}^n \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right].$

%Since, each couple $(x_i,y_i)$, for $ 1\leq i \leq n$ is chosen randomly  according to the  probability distribution measure $\mu$. Without loss of generality, for instance, let us assume that the couple $(x_i,y_i)$ is chosen independently. Then, the winning probability becomes: 
%
%$$\Pr \left[\bigwedge\limits_{i=1}^n \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right]= \prod\limits_{i=1}^n \Pr \left[ \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right].$$
%\Jnote{No, this is wrong. $x_i, y_i$ is always chosen independently, you
%  don't have to ``assume'' this. But this does not imply
%  your equation. The equation is wrong.}


Let us chose the optimal strategies $f$ and $h$ of $G$ to play each parallel copy of $G$, that is $f_i (\bar{x})=f(x_i)$ and $h_i (\bar{y})=h (y_i)$ for $ 1\leq i \leq n$. Then, the success probability becomes:
\begin{align*}
\Pr \left[\bigwedge\limits_{i=1}^n \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right] = &   \prod\limits_{i=1}^n \Pr \left[ \phi (x_i,y_i, f(\bar{x}), h(\bar{y}))=1 \right] =  \prod\limits_{i=1}^n \val (G) \\
= & \val (G)^n.
\end{align*}
%\Jnote{Here the equation becomes true, but the reason for that is   that $f_i, h_i$ depend only on $x_i, y_i$. Otherwise it is false.} 

$(f,h)$ is the optimal couple of strategies for the game $G$, this does not means that the couple $(F,H)$  is the optimal couple of the strategies for the parallel repetition $G^n$. Then, the winning probability for $G^n$ over the optimal couple of strategies is:
\begin{align*}
\val (G^n)= & \max\limits_{F,H} \Pr \left[\bigwedge\limits_{i=1}^n \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right] 
 \geq  \Pr \left[\bigwedge\limits_{i=1}^n \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right] \\
 = & \prod\limits_{i=1}^n \Pr \left[ \phi (x_i,y_i, f(\bar{x}), h(\bar{y}))=1 \right]  =  \prod\limits_{i=1}^n \val (G)  =  \val (G)^n .
\end{align*}

Hence, $\val (G^n) \geq \val (G)^n.$
\end{proof}

\item The second inequality: $\val (G^n) \leq \val (G).$
\begin{proof}
 \begin{align*}
 \val (G^n) & = \max\limits_{F,H} \Pr \left[\bigwedge\limits_{i=1}^n \phi (x_i,y_i, f_i(\bar{x}), h_i(\bar{y}))=1 \right] \leq Pr \left[ \phi (x_1,y_1, f_1(\bar{x}), h_1(\bar{y}))=1 \right] \\
 &  \leq \max\limits_{f,g} \Pr[\phi(x_1,y_1,f(x),h(y))=1]  = \val (G).
 \end{align*}
 %\Jnote{\text{The second equation above is not true.}}
%\Jnote{In the equations above, indicate over what the probability is taken.}
Hence, $\val (G^n) \leq \val (G).$
\end{proof}
\end{itemize}

\subsection{Example}
As illustration for a two-prover game $G$, the following example supports the relation  $\val (G)^n \leq \val (G^n) \leq \val (G)$.

Let $G$ be a two-prover game and  $X=Y=\{0,1\}$ be sets of questions addressed respectively to prover $A$ and $B$. The rule of the game $G$ is announced as this. The verifier $\phi$ chooses randomly and uniformly a couple of questions $(x,y) \in Q=X \times Y=\{(0,0);(0,1);(1,0);(1,1)\}$ and sends $x$ to the prover $A$ and $y$ to the prover $B$. The sets of answers of the  two provers are  respectively  $S=\{(a,K_A)\}$ and $T=\{(b,K_B)\}$ where $a,b \in \{0,1\}$,  $K_A,K_B \in \{A,B\}$. Note that $|S|=|T|=4.$ To win, the verifier checks this: \begin{itemize}
\item $K_A=K_B=K$ and $a=b$.
\item  If $K=A$, then $x=a$, that is,  if both provers answer $A$ then the  first component of the couple of  answers of the provers is $x=a=b$.
\item If $K=B$, then $y=b$, that is,  if both provers answer $B$ then the  first component of the couple of  answers of the provers is $y=a=b$.
\end{itemize}
This means that the winning cases are: $\phi[x,y, (x,A), (x,A)]$ and $\phi[x,y, (y,B), (y,B)]$.

Let us define a couple of strategies $(f,g)$ used by the two players to answer as following:  $f(0)=(0,A), f(1)=(1,A)$ and  $g(0)=(0,A), g(1)=(1,A)$.
 Let us evaluate the probability to win this game. In our strategy, we always have $K_A=K_B=A$ in the second component of the answer. So, the two provers can win in two cases: $(0,0)$ and $(1,1)$. They also lose  in two cases: $(0,1)$ and $(0,1)$. Hence, the winning probability of the game according to this couple of strategies is: $\Pr [\phi(x,y, (a,K_A), (b,K_B))=1]=\frac{2}{4}=\frac{1}{2}.$
 
 Let us define another couple of strategies $(s,t)$ such that $s(0)=(0,A), s(1)=(0,A)$ and  $t(0)=(0,A), t(1)=(0,A)$. For this couple of strategies, the two provers can win in two cases: $(0,0)$ and $(0,1)$. They also lose  in two cases: $(1,0)$ and $(1,1)$. Hence, the winning probability of the game according to this couple of strategies is: $\Pr [\phi(x,y, (a,K_A), (b,K_B))=1]=\frac{2}{4}=\frac{1}{2}.$

For all possible couple of strategies, the maximum value of the winning probability is $\frac{1}{2}$. Therefore, the value of the game $G$  is: $$\val (G)= \frac{1}{2}.$$
 
Now, let us compute $\val (G^2).$ Firstly, let us define the game $G^2.$

The sets of questions are respectively $X^2=Y^2=\{(0,0);(0,1);(1,0);(1,1)\}.$ The verifier chooses randomly and uniformly the couple $(\bar{x}, \bar{y}) \in Q=X^2 \times Y^2=\{(\bar{x}, \bar{y}): \bar{x} \in X^2, \bar{y} \in Y^2 \}=\{((0,0),(0,0)), \ldots,  ((1,1),(1,1))\}$ where $\bar{x}=(x_1,x_2)$ and $ \bar{y}=(y_1,y_2)$ are couples with $x_1, x_2, y_1, y_2 \in \{0,1\}$. Note that $|Q|=16.$ The sets of answers are :$S^2=\{(\bar{s}_1, \bar{s}_2): \bar{s}_1, \bar{s}_2 \in S\}=   \{((a,K_A), (a,K_A)): a \in \{0,1\}, K_A \in \{A,B\} \}$ and $T^2=\{(\bar{t}_1, \bar{t}_2): \bar{t}_1, \bar{t}_2 \in T\}= \{((b,K_B), (b,K_B)): b \in \{0,1\}, K_B \in \{A,B\} \}$. The verifier sends $\bar{x}$ to prover $A$ and $\bar{y}$ to prover $B$. Answers of $\bar{x}$ is in $S^2$ and answers of $\bar{y}$ is in $T^2$. 

%\Jnote{No, the verifier checks rules for $G$ as before. These conditions   are just for the strategy below.}

For that, let us define a couple of strategies $(h,k)$ such that $h(\bar{x})=h(x_1,x_2)=((x_1,A),(x_1,B))$ and $k(\bar{y})=k(y_1,y_2)=((y_2,A),(y_2,B))$.
%\Jnote{There is a typo here.}

According to this couple of strategies and to the game $G$, both provers $A$ and $B$ win if $x_1=y_2$. Otherwise they lose. Namely, firstly we have shown in \eqref{prtp} that the element  $((x_1, y_1),(x_2,y_2 ), \ldots, (x_n, y_n)) \in Q^n$ can be identified to the pair $((x_1,\ldots, x_n), (y_1, \ldots, y_n)).$ Then, when $x_1=y_2$, for the first couple of questions $(x_1,y_1)$, the verifier will accept because in the second component of the answer $K_A=K_B=A$, and  in the first component of the answer $x_1=y_2$. Equally, the verifier will accept the answer of the second couple of questions $(x_2,y_2)$ because $K_A=K_B=B$ and $x_1=y_2.$

Hence, both provers $A$ and $B$ win in each column of the table \eqref{wc}.
%\Jnote{You have to explain why according to rules of the game.}
\begin{table}[h]
\centering
\begin{tabular}{c|cccccccc} 
A & (0,0) & (0,0) &( 0,1) & (0,1) & (1,0) & (1,0) & (1,1) & (1,1) \\ 
\hline 
B & (0,0) & (1,0) & (0,0) & (1,0) & (0,1) & (1,1) & (1,1) & (0,1) 
\end{tabular} 
\caption{Winning cases for provers $A$ and $B.$} \label{wc}
\end{table}

And both provers $A$ and $B$ lose in each column of the table \eqref{lc}.
\begin{table}[h]
\centering
\begin{tabular}{c|cccccccc} 
A & (0,0) & (0,0) &( 0,1) & (0,1) & (1,0) & (1,0) & (1,1) & (1,1) \\ 
\hline 
B & (0,1) & (1,1) & (0,1) & (1,1) & (0,0) & (1,0) & (0,0) & (1,0) 
\end{tabular}
\caption{Losing cases for provers $A$ and $B.$} \label{lc}
\end{table} 

Then, the winning probability of the game $G^2$ according to the couple of strategies $(h,k)$ is $\frac{8}{16}=\frac{1}{2}.$

For all couple of strategies, we assume that the winning probability is less or equal to $\frac{1}{2}.$

Thus, the value of the game $G^2$  is: $$\val (G^2)=\frac{1}{2}.$$

Therefore, $\val (G)^2\leq \val (G^2) \leq \val (G).$

%\Jnote{I think it is very important that you give some examples  illustrating the problem. Try finding a simple game $G$  such that $\val(G^2) > \val(G)^2$.}


\subsection{Parallel repetition theorem of two-prover games}

The parallel repetition theorem of  two-prover games presents an  approximation upper bound of the value of $n$ independent copies of the game $G$.
Many main topics on the parallel repetition of prover game started to be treated from the early 1990s. 

\cite{feige1992two} conjectured that  for any two-prover game $G$ with value smaller than 1 ($\val (G)<1$), the value of the game $G^n$ ($\val (G^n$) decreases exponentially fast to 0.

We denote by $|S|$ and $|T|$ respectively the size of the sets of answers $S$ and $T$ of the game $G$. Thus, the  answer  size of the game $G$ is $|S||T|$.
%\Jnote{No, size of the game is usually something else. Delete this.}
Let us denote by $c$ a universal constant and by $s$ the expression  $s(G)=\log |S||T|$ which represents the length of the answers. $s$ can also represent the  answer size.
The parallel repetition theorem as formulated in \cite{raz1998parallel,raz2010parallel} is stated as follows:

\begin{thm} For any two-prover game $G$, with $\val (G) \leq 1-\epsilon$, for $0 < \epsilon \leq 1$, the value of the game $G^n$ is: $$ \val (G^n) \leq (1-\epsilon^c)^{\Omega(n/s)}.$$ \label{prt}    \end{thm}

Knowing that for all real number, $1+x \leq e^x$ and
for $x$ closer to zero:  $e^x = 1+x+O(x^2)$ or simply  $1+x \approx e^x$,
%\Jnote{Write it differently: you can say that for $x$ close to $0$:  $1+x\approx e^x$, or, more precisely,   $e^x = 1+x+O(x^2)$.}
the bound of $\val (G^n)$ as expressed in \eqref{prt} can be rewritten as follows:

$\val (G^n) \leq  (1-\epsilon^c)^{\Omega(n/s)}  \leq  \left(e^{-\epsilon^c}\right)^{\Omega(n/s)}  =  \exp (-\epsilon^c \Omega(n/s)).$
 Then, $\val (G^n) \leq \exp (-\epsilon^c \Omega(n/s)).$
Or $
\val (G^n) \leq  \exp (-\epsilon^c \Omega(n/s))   =  \exp (-\epsilon \epsilon^{c-1} \Omega(n/s)) = \exp (-\epsilon)^{\epsilon^{c-1} \Omega(n/s)}  \approx   (1-\epsilon)^{\epsilon^{c-1} \Omega(n/s)}.$ 
Then, $\val (G^n) \leq (1-\epsilon)^{\epsilon^{c-1} \Omega(n/s)}.$
%\Jnote{Typo in the last line.}

In some papers, the authors, for instance \cite{rao2011parallel}, express the upper bound of $\val (G^n)$ by using this expression: $\val (G^n) \leq (1-{\epsilon}/{2})^{  \epsilon^{c} \Omega(n/s)}.$
%\Jnote{Something is confused here. Why $\epsilon^{c-1}$?   You should use $\exp(-\epsilon/2) \le (1-\epsilon)$ (for what $\epsilon$?),   where is it?}

\cite{feige1992two} conjectured the parallel repetition theorem and gave some proofs for some special cases. The proof of the theorem \eqref{prt}  has been given by \cite{raz1998parallel} and found an implicit constant   $c=32$.  \cite{holenstein2007parallel} simplified Raz's proof, proved the parallel repetition theorem in case of no-signaling strategies (strategies which do
not imply communication) and gave an explicit bound on the maximal success probability of the product game $G^n.$ This explicit bound is expressed as:
$$\val (G^n) \leq \left(1-\frac{(1-\val (G))^3}{6000} \right)^{\frac{n}{\log (|A||B|)}}.$$
%\Jnote{Dot after math mode.}
This means that the constant $c=3$ in Thomas Holenstein's bound which is better than Ran Raz's expression. However, for the special case of the projection games. 
\cite{rao2011parallel} improved the bound of this game by finding $c=2$ and by expressing the function $\Omega$ without $s.$ This bound is: $$\val (G^n) \leq (1-\epsilon^2)^{\Omega(n)}.$$ According to \cite{raz2010parallel}, this bound was also known for the special case of XOR games.

To improve this bound from \eqref{prt} to $(1-\epsilon)^{\Omega(n/s)}$ for the $n$-product game of two-prover games or for some special cases  is one of the questions for which several researchers are looking for answers \citep{raz2010parallel}.  This question is called the \textit{strong parallel repetition problem}.

In case if the probability distribution on $X \times Y$ is a product distribution  for games , \cite{barak2009strong}  showed that the value of free game is bounded  as follows:
 $$\val (G^n) \leq (1-\epsilon^2)^{\Omega(n/s)}$$
 and if the game is a free projection game, then the value of the game is: $$\val (G^n) \leq (1-\epsilon)^{\Omega(n)}.$$
Hence, the strong parallel repetition for the free projection game that is with product distribution is known. Note that the function $\Omega$ is not depending on $s.$

Similarly, \cite{raz2012strong} studied the case where the probability distribution is uniform over the edges of an expander graph. The value of the repeated game is:
$$\val (G^n) \leq (1-\epsilon^2)^{c(\lambda). \Omega(n/s)}$$ where $\lambda$ is the normalized spectral gap of the expander  graph and $c(\lambda)=\poly (\lambda).$ 

If in addition the game is a projection game, then the value of the repeated game is: $$\val (G^n) \leq (1-\epsilon)^{c(\lambda). \Omega(n)}$$ which is  a strong parallel repetition for a projection games on expander graph.

However, \cite{raz2011counterexample} gave a negative answer to the several research who are asking if it is possible to found a strong parallel repetition for two-prover games, that is to improve the bound value to  $(1-\epsilon)^{\Omega(n/s)}.$ A counterexample to strong parallel repetition used to disprove is an \textit{odd cycle game} of size $m$ which is a two-prover game with value $1-1/2m.$ Thus, Raz showed that
%\Jnote{s/Thus,/Raz showed that}
the value of the parallel repetition of this odd cycle game is at least $1-(1/m).O(\sqrt{n})$. Hence, for large $n = \Omega(m^2)$, the value of  the parallel repetition ($n$ times) of this odd cycle game is at least $(1-1/4m^2)^{O(n)}$.
%\Jnote{I don't understand how you computed this.}
That is, the lower bound value of parallel repetition of two-prover games is at least $(1-\epsilon^2)^{O(n)}$ and can not reach $(1-\epsilon)^{\Omega(n/s)}.$

Since the odd cycle game is a projection game, a unique game, and a XOR game, this answers negatively most
variants of the strong parallel repetition problem \citep{raz2011counterexample, raz2012strong}. That is there exists a two-prover game (odd cycle game) which does not have a strong parallel repetition theorem. 

Moreover, \cite{dinur2014analytical} used projection games to study parallel repetition by using analytical approach based on a matrix analysis argument. Their
%\Jnote{s/His/Their}
result state that for every projection game $G$ with $\val (G) \leq \rho$, we have:  \begin{align}
\val (G^n) \leq \left(\frac{2\sqrt{\rho}}{1+\rho} \right)^{n/2}. \label{st}
\end{align}
\cite{dinur2014analytical} establishes that this upper value  bound \eqref{st} of an $n$- fold parallel repetition of projection games $G$ and  $(1-\epsilon^2)^{O(n)}$  
%\Jnote{Which bound by Rao? Give equation number.}
with improved bounds from  \cite{rao2011parallel} match when the value of the game $G$ is closed to 1.

Notice that the good things of those approximations of the upper value of the parallel repetition, is that,  the value of the game $G^n$ is reduced exponentially.

In this work, we are mainly interested by the upper bound of the value of the parallel repetition.  However, 
there exists some works which approximate the lower bound \citep{feige2007understanding,steurer2010improved, raz2011counterexample}. The table \eqref{bkp} adapted from \cite{tamaki2015parallel} presents a summary of lower and upper bounds known of parallel repetition of some two-prover games.

%\Jnote{Typo in the first row of first table. What is ``Projection on expander games''?}

\begin{table}[h]

\resizebox{\textwidth}{!}{\begin{tabular}{lll}
\hline 
\textbf{Upper bounds} &\textbf{ Kind of game $G$} & \textbf{References} \\ 
\hline 
$(1-\epsilon^{32})^{\Omega(n/s) }$& All provers &  \cite{raz1998parallel} \\ 
$(1-\epsilon^3)^{\Omega(n/s) }$&  All provers &  \cite{holenstein2007parallel} \\ 
$(1-\epsilon^2)^{\Omega(n) }$&  Projection, xor & \cite{rao2011parallel,raz2010parallel}\\
$\left(\frac{2\sqrt{\rho}}{1+\rho} \right)^{n/2}$ & Projection & \cite{dinur2014analytical} \\
$(1-\epsilon^2)^{\Omega(n/s) }$& Free & \cite*{barak2009strong}\\
$(1-\epsilon)^{\Omega(n) }$ & Free projection & \cite*{barak2009strong}\\
$(1-\epsilon^2)^{c(\lambda). \Omega(n/s) }$& Expander with spectral gap $\lambda$ & \cite{raz2012strong}\\
$(1-\epsilon)^{c(\lambda). \Omega(n) }$& Projection on Expander games & \cite{raz2012strong}\\
\hline \\
\hline
\textbf{Lower bounds} & \textbf{Kind of game $G$} & \textbf{Reference} \\ 
\hline 
$1-(1/m).{O(\sqrt{n})}$& Odd cycle, value $1-1/m$ & \cite*{feige2007understanding}\\
$(1-1/4m^2)^{O(n)}$& Odd cycle, $n\geq \Omega(m^2)$ & \cite{raz2011counterexample}\\
$1-O(\sqrt{\epsilon ns})$ & Unique & \cite{steurer2010improved} \\
\hline 
\end{tabular} }
\caption{Summary of known bounds} \label{bkp}
\end{table}



\subsection{Parallel repetition of multi-prover games}
%\Jnote{s/mutli/multi}

Let $G(\phi, Q \subset X^1 \times \ldots \times X^k, A^1, \ldots, A^k, \mu)$ be a $k$-prover game, that is a prover game played with $k$ players. For $1 \leq t \leq k$, the sets $X^t$ and $A^t$ represent respectively the set of questions and the set of their answers. The verifier $\phi$ is a predicate  defined on $\left( \prod\limits_{t=1}^k X^t, \prod\limits_{t=1}^k A^t \right)$, that is $\phi [(x^1, \cdots , x^k),(a^1, \cdots , a^k)]=1$ for a winning case and  the other for the losing case. The distribution measure $\mu$ is a function defines from $Q$ to $(0,1].$
%\Jnote{What happened to $Q$?}

The $n$-fold parallel repetition of the game $G$ is the $k$-prover game $G^n(\phi^n, Q^n \subseteq (X^1)^n \times \ldots \times (X^k)^n, (A^1)^n, \ldots,( A^k)^n, \mu^n)$, where  $(X^1)^n , \ldots, (X^k)^n$ are sets of $n$-tuple of questions, $(A^k)^n , \ldots, (A^k)^n$ are sets of $n$-tuple of answers. 

Let us denote by $x_i^t$ an element of the set $X^t$ where superscripts $1\leq t \leq k$   denote the players and subscripts $1 \leq i \leq n$  denote  coordinates in parallel repetition.

Elements of $Q^n$ are $n$-tuple of $k$-tuple (of questions). 

The element $((x_1^1, \cdots , x_1^k), (x_2^1, \cdots , x_2^k),\ldots, (x_n^1, \cdots , x_n^k))$ $ \in_{\mu^n} Q^n$ can be identified to the $k$-tuple $((x_1^1, \cdots , x_n^1), (x_1^2, \cdots , x_n^2),\ldots, (x_1^k, \cdots , x_n^k))$. Elements of $Q^n$ are chosen randomly  in accordance with the probability distribution $\mu^n$. Let $\bar{x}^t$ represent a $n$-tuple $(x_1^t, \cdots , x_n^t)$ belongs to $(X^t)^n$.
%\Jnote{Belongs to $Q^n$? I think it is $(X^t)^n$.}
So, the distribution measure $\mu^n$ is a function defined as:
\begin{align*}
\mu^n:  & Q^n \subseteq (X^1)^n \times \ldots \times (X^k)^n   \longrightarrow (0,1] \\
  & (\bar{x}^1,\ldots, \bar{x}^k) \longmapsto \mu^n(\bar{x}^1,\ldots, \bar{x}^k)=\prod_{i=1}^n  \mu (x_i^1, \cdots , x_i^k). 
 \end{align*}

And  the verifier is a predicative defined as follows:
\begin{align*}
\phi^n: &(X^1)^n \times \ldots \times (X^k)^n \times (A^1)^n \times \ldots \times ( A^k)^n)  \longrightarrow  \{0,1\}\\ 
& (\bar{x}^1,\ldots, \bar{x}^k,\bar{a}^1, \ldots, \bar{a}^k)  \longmapsto  \phi^n (\bar{x}^1,\ldots, \bar{x}^k,\bar{a}^1, \ldots, \bar{a}^k) = \bigwedge\limits_{i=1}^n \phi [x_i^1, \cdots , x_i^k, f_i^1(\bar{x}^1), \cdots ,  f_i^k(\bar{x}^k)]
\end{align*}
where $\bigwedge$ represents the logical connective "AND" (conjunction) and $f_i^t$ are strategies.

There are two results: win or lose. All $k$ provers win when $ \bigwedge\limits_{i=1}^n \phi [x_i^1, \cdots , x_i^k, f_i^1(\bar{x}^1), \cdots ,  f_i^k(\bar{x}^k)]=1$, that is when all provers win simultaneously in all $n$ coordinates. The verifier treats independently each of the $n$ copies. 

As  all provers are allowed to agree on a strategy but not to communicate each other during the game, the strategy in this case is a $k$-tuple of functions $(F^1,F^2, \ldots, F^k)$ where for $1\leq t \leq k$, every $F^t$ is an $n$-tuple function $(f_1^t, f_2^t, \ldots, f_n^t)$. $f_i^t$ is strategy used by the prover $t$ to give the answer $a_i^t$ of the question $x_i^t$ for $1\leq i \leq n$. This function $f_i^t$ is defined as:
\begin{align*}
f_i^t: & (X^t)^n \longrightarrow A^t \\ & \bar{x}^t \longmapsto f_i^t(\bar{x}^t)=a_i^t
\end{align*}
%\Jnote{No! $f_i^t: (X^t)^n \to A^t$}

Thus, the value of the parallel repetition of the multi-prover game G denoted by $\val(G^n)$ is the optimal winning probability of provers over all possible strategies. This value is expressed as follows: 
$$ \val (G^n)= \max_{F^1,F^2, \ldots, F^t} \Pr \left[  \bigwedge\limits_{i=1}^n \phi \left( x_i^1, \cdots , x_i^k, f_i^1(\bar{x}^1), \cdots ,  f_i^k(\bar{x}^k) \right)=1 \right].$$


Given the value of the multi-prover game $G$, can we estimate or approximate the value of the parallel repetition of the multi-prover game $G$ using the value of $G$? 

For a two-prover game, there are so many advanced studies about that, we can cite the works of \cite{feige1992two, verbitsky1996towards,raz1998parallel, holenstein2007parallel, barak2009strong,raz2010parallel, rao2011parallel,dinur2014analytical}.  Nevertheless, express $\val (G^n)$  in terms of power of $\val (G)$ or bound it with the power of $\val (G)$ does not seem to be easy.

 Another question that we can ask is: does the value of parallel repetition of a multi-prover game decay exponentially like for a two-prover game?

For some multiplayer games, for instance free game and anchored\footnote{ Related to quantum parallel repetition. Before being repeated in parallel, the base game $G$ is modified to an equivalent game $\tilde{G}$.} game, the exponentially decay bounds for parallel repetition are known \citep{barak2009strong,bavarian2015anchoring}.  A recent work of \cite{dinur2016multiplayer} gives an exponentially decay bound for the parallel repetition for  expander games. 

Expander game is based on expander graph (see \eqref{expander}).  Given a base game $G$, a related connected graph $G$, a spectral gap of the graph $G$ denoted by $\lambda$,  then the value of the repeated game, $\val (G^n)$  goes down exponentially in $n$ for sufficiently large $n$. \cite{dinur2016multiplayer} expresses it as follows:
\begin{align}
\val (G^n) \leq \exp \left(-\frac{c \epsilon^5 \lambda^2 n }{\log |A|}\right) \label{exp}
\end{align}
where $|A|$ is the answer size of the game and $c$ a constant.

An expander game is  merely the extension of free and anchored games. All kind of expander games are linked by the connectedness property. Hence, the free and anchored games are connected games. 

As $0 < \epsilon \leq 1$, $\epsilon^5$ is very smaller than $\epsilon$. The upper bound value \eqref{exp} of the parallel repetition of the expander game can be expressed as:
\begin{align*}
\val (G^n) & \leq \exp \left(-\frac{c \epsilon^5 \lambda^2 n }{\log |A|}\right) =\exp \left(-\epsilon^5\right)^{\frac{c  \lambda^2 n }{\log |A|}} =(1-\epsilon^5)^{ \frac{c  \lambda^2 n }{\log |A|}} =(1-\epsilon^5)^{ \Omega(n/s)}
\end{align*}
where $s=\log |A|$ and $\Omega(n/s)=\frac{c  \lambda^2 n }{\log |A|}$ with  $\lambda$ a constant.

A general bound of the value of parallel repetition of a multi-prover game is  given by  \cite{verbitsky1996towards} by using the Hales-Jewett theorem. Despite the fact that the rate of  convergence of this general bound value of Oleg Verbitsky is slow, this boundary  remains the only best result that gives a general parallel repetition bound for all multiplayer games \citep*{hkazla2016forbidden,dinur2016multiplayer}. In the following chapter, we present the connection between Hales-Jewett theorem and the parallel repetition of  multi-prover games. 
%\Jnote{Don't use et al. for citing.}

 
 