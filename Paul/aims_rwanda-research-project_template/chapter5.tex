\chapter{Conclusion}
\begin{flushleft}
The era of topic modelling gave rise to some number of topic modelling approaches, the vector space model (VSM), latent semantic analysis (LSA), latent dirichlet allocaton (LDA) etc. This research employed the LDA to summarise reports from the international federation of red cross and crescent society. The LDA model takes a number of parameters, notably the number of topics. The model outputs the exact number of topic number inputs. The quality of the topics that the LDA generates also depends on the other parameters. Our work assigned the model to generate 30 topics. We observed that the model is random in generating the topics. In the sense that when the input parameters are maintained and the model command is executed several times, different but similar set of topics are obtained. The observed difference is that, some number of new topics replaces some topics that occurred in previous results. This means that the model can generate  many topics, depending on the "topic number" parameter value assigned in the model. Hence there exist more than 30 topics in the corpus.
\end{flushleft}
\begin{flushleft}
In spite of the fact the LDA gave some good results, the results could have been better if some techniques had been applied during the data preprocessing stage. Techniques such as lematization and stemming aimed at grouping words together from one root and assigning base word to them. For example, topic 18 has the words "donors" and "donations". With lematization the two words can reduced to their base form as "donor", so that wherever in the corpus these words are replaced by "donor".  
Future work will incorporate these techniques to improve the quality of results.
\end{flushleft}