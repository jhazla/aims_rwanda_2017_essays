\chapter{Introduction}

%\Jnote{Some general comments:}
%
%\Jnote{Read everything you write again, for example one day after it is written.
%  Read every sentence carefully and check if it makes sense.
%  Correct grammar errors, typos and punctuation.}
%
%\Jnote{I said this many times: while you are writing a summary, you are not
%  supposed to be looking at the paper you are summarizing. Many sentences in sections
%  on LDA are too close to sentences from Blei paper.}
%
%\Jnote{It is not acceptable to copy pictures without clearly indicating the source.
%  In my opinion, for an essay it is not acceptable to copy pictures at all
%  unless you have a very good reason. Yabebal might disagree with me,
%  please clarify with him.}

%In today's world where the most popular and convenient %way of storing information is the electronic storage.
This research is interested in how information can be accessed easily from a large chunk
\Jnote{s/chunk/collection}
of data. As the stored data increases,
\Jnote{s/stored data increases/amounts of stored data increase}
we are faced with the challenge and the difficulty in trying to explore and extract what we need.
For the purpose of easily understanding the contents of the data or know
\Jnote{s/know/knowin}
what it talks about, topic models serves as a tool for handling this task.
\Jnote{Rephrase: ``Topic models serve as tools for the purpose...''}

Topic models are statistical tools with a collection of algorithms that reveals
\Jnote{s/reveals/reveal}
the key components to understanding a document. Huge magnitude of unlabelled text can be analysed with a topic model.

Topic model algorithms provides the environment that allows
\Jnote{s/provides/provide}
users to explore the text in details and summarize it no matter how large their size. Topic model is very useful in identifying the patterns of words in a document and in the event that more than one document is involved in the ML, documents with similar patterns can be related.
\Jnote{Change ``ML'' to ``machine learning''.}

Topic models are unsupervised method of ML,
\Jnote{Full stop here. Later: ``Through various algorithms, they are able to...''}
through various algorithms is able to produce cluster of words that represent somewhat a summary of a document. They are applied in search engines to recommend to users what they are interested in. A typical summary for a collection of documents is for the analysis of web search, producing results for users in further search \citep{turpin2007fast}.
\Jnote{I didn't get last sentence.}

This research focuses on summarizing reports from the international federation of red cross and crescent societies (IFRC).
\Jnote{Capitalize: International Federation of Red Cross and Crescens Societies.}
\Jnote{Do not jump between topics. Put information about IFRC after the formula
  with $L$ and $S$.}
The summary provides  a  representative topic for each document or in other words best cluster of words that summarize the document. Mathematically, it can be perceived as a function that takes a large text and converts to small one, in a way that thematic structure of the large original document is preserved.This can be represented as :

$$f:L \longrightarrow S, \quad \text{Such that} \quad |S|<< |L| \cdot$$
\Jnote{Also use ``\textbackslash ll'' instead of $<<$.}
$L=$ Large text or document

$S=$ Summarized document or small document.
  
Intuitively the size of $S$ is smaller than $L$.
Manually going through the reports and trying to understand what each is talking about can be time consuming and challenging. The IFRC is a non-governmental organization
that provides humanitarian assistance to victims who suffers
\Jnote{s/suffers/suffered}
a disaster event. Through this aid the 	IFRC generates data of the occurrences of disaster
\Jnote{s/disaster/disasters}
worldwide. Large volumes of complex information    are locked in the reports and it is hard extracting
\Jnote{s/extracting to extract}
them going by the manual approach. 
%Presently a number of research have been %carried out in topic modelling, Nagwani %(2015) conducted a research in this area %based on the model known as MapRule. 

This research will employ the Latent Dirichlet Algorithm (LDA).
 The LDA model extract the contextual meaning from a given large text. 

 This research is divided into five chapters, the second chapter elaborates some key concepts of topic modelling, IFRC and similar work. The third chapter discuss
 \Jnote{s/discuss explicitly LDA/discusses LDA explicitly}
 explicitly LDA,  and the tools that were also used to arrive at the final results. The fourth chapter covers results and discussions. Chapter five presents conclusion and recommendation.
 
